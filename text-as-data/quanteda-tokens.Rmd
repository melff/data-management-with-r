# Obtaining tokens in text documents using *quanteda*

```{r}
options(jupyter.rich_display=FALSE) # Create output as usual in R
```

The following makes use of the *quanteda* package. You may need to install it from
[CRAN](https://cran.r-project.org/package=quanteda) using the code
`install.packages("quanteda")` if you want to run this on your computer. (The
package is already installed on the notebook container, however.)

```{r}
library(quanteda)
```

```{r}
quanteda_options(print_tokens_max_ndoc=3,
                 print_tokens_max_ntoken=6)
```

The following makes use of an example corpus which is part of the *quanteda* package.

```{r}
inaugural_toks <- tokens(data_corpus_inaugural)
inaugural_toks
```

```{r}
inaugural_ntoks <- sapply(inaugural_toks,
                          length)
inaugural_ntoks <- cbind(docvars(inaugural_toks),
                         ntokens = inaugural_ntoks)
```

```{r}
with(inaugural_ntoks,
     scatter.smooth(Year,ntokens,
                    ylab="Number of tokens per speech"))
```

```{r}
inaugural_sntc <- corpus_reshape(data_corpus_inaugural,
                                 to="sentences")
inaugural_sntc_toks <- tokens(inaugural_sntc)
inaugural_sntc_ntoks <- sapply(inaugural_sntc_toks,
                               length)
inaugural_sntc_ntoks <- cbind(docvars(inaugural_sntc_toks),
                              ntokens = inaugural_sntc_ntoks)
```

```{r}
inaugural_sntc_ntoks <- aggregate (ntokens~Year,mean,
                                data = inaugural_sntc_ntoks)
```

```{r}
with(inaugural_sntc_ntoks,
     scatter.smooth(Year,ntokens,
                    ylab="Number of tokens per sentence"))
```
