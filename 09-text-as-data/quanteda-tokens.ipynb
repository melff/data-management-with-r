{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining tokens in text documents using *quanteda*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following makes use of the *quanteda* package. You may need to install it from\n",
    "[CRAN](https://cran.r-project.org/package=quanteda) using the code\n",
    "`install.packages(\"quanteda\")` if you want to run this on your computer. (The\n",
    "package is already installed on the notebook container, however.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(quanteda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quanteda_options(print_tokens_max_ndoc=3,\n",
    "                 print_tokens_max_ntoken=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following makes use of an example corpus which is part of the *quanteda* package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inaugural_toks <- tokens(data_corpus_inaugural)\n",
    "inaugural_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inaugural_ntoks <- sapply(inaugural_toks,\n",
    "                          length)\n",
    "inaugural_ntoks <- cbind(docvars(inaugural_toks),\n",
    "                         ntokens = inaugural_ntoks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with(inaugural_ntoks,\n",
    "     scatter.smooth(Year,ntokens,\n",
    "                    ylab=\"Number of tokens per speech\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inaugural_sntc <- corpus_reshape(data_corpus_inaugural,\n",
    "                                 to=\"sentences\")\n",
    "inaugural_sntc_toks <- tokens(inaugural_sntc)\n",
    "inaugural_sntc_ntoks <- sapply(inaugural_sntc_toks,\n",
    "                               length)\n",
    "inaugural_sntc_ntoks <- cbind(docvars(inaugural_sntc_toks),\n",
    "                              ntokens = inaugural_sntc_ntoks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inaugural_sntc_ntoks <- aggregate (ntokens~Year,mean,\n",
    "                                data = inaugural_sntc_ntoks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with(inaugural_sntc_ntoks,\n",
    "     scatter.smooth(Year,ntokens,\n",
    "                    ylab=\"Number of tokens per sentence\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
