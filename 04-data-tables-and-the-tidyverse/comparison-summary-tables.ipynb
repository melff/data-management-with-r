{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of the benchmark study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following makes use of the packages *data.table*, *dplyr*, *memisc*, and *rbenchmark*. You may need to install these packages from [CRAN](https://cran.r-packages.org) by calling `install.packages(c(\"data.table\",\"dplyr\",\"memisc\",\"rbenchmark\"))` if you want to run this on your computer. (The packages are already installed\n",
    "on the notebook container, however.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(data.table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(memisc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(rbenchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_matrix <- function(x){\n",
    "    rn <- x$test\n",
    "    x <- as.matrix(x[,-1])\n",
    "    rownames(x) <- rn\n",
    "    x\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load(\"grouped-summary-benchmark.RData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_summary_benchmark_1 <- bench_matrix(grouped_summary_benchmark_1)\n",
    "grouped_summary_benchmark_2 <- bench_matrix(grouped_summary_benchmark_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_summary_benchmark <- memisc::collect(\n",
    "    \"`Big data'\"    = grouped_summary_benchmark_1,\n",
    "    \"`Survey data'\" = grouped_summary_benchmark_2)\n",
    "grouped_summary_benchmark <- grouped_summary_benchmark[-5,,]\n",
    "colnames(grouped_summary_benchmark) <- c(\"abs.\",\"rel.\")\n",
    "names(dimnames(grouped_summary_benchmark)) <- c(\"Method\",\"Timing\",\"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(jupyter.rich_display=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftable(grouped_summary_benchmark,col.vars=3:2) %>% memisc::show_html(digits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load(\"grouped-modification-benchmark.RData\")\n",
    "\n",
    "grouped_modification_benchmark_1 <- bench_matrix(grouped_modification_benchmark_1)\n",
    "grouped_modification_benchmark_2 <- bench_matrix(grouped_modification_benchmark_2)\n",
    "\n",
    "grouped_modification_benchmark <- collect(\n",
    "    \"`Big data'\"    = grouped_modification_benchmark_1,\n",
    "    \"`Survey data'\" = grouped_modification_benchmark_2)\n",
    "colnames(grouped_modification_benchmark) <- c(\"abs.\",\"rel.\")\n",
    "names(dimnames(grouped_modification_benchmark)) <- c(\"Method\",\"Timing\",\"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftable(grouped_modification_benchmark,col.vars=3:2) %>% memisc::show_html(digits=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
